{
  "hash": "bc3b6f884e6224bf86f44d0a931cdcbf",
  "result": {
    "engine": "julia",
    "markdown": "---\nengine: julia\n---\n\n# Linearization\n\n\n\n\n## 対数変化率\n\n::: {#prp-fact-1}\n\nある実数 $m$ が0に近い時, 以下の近似が成り立つ.\n\n$$\n\\log(1 + m) \\approx m.\n$$\n\n:::\n\nこの時, $\\hat{x}_t$ を定常状態 $x$ からの対数変化率とすると:\n\n$$\n\\begin{aligned}\n\\hat{x}_t &:= \\log x_t - \\log x \\\\\n&= \\log\\left(\\frac{x_t}{x}\\right) \\\\\n&= \\log\\left(1 + \\frac{x_t - x}{x}\\right) \\\\\n&\\approx \\frac{x_t - x}{x} \\\\\n\\end{aligned}\n$$\n\nこの, $\\frac{x_t - x}{x}$ という量は, 定常状態 $x$ からの変化率を表す量です. したがって, $\\hat{x}_t = 0.01$ であれば, 定常状態 $x$ から1%の変化があったことを意味します. 論文によって, $\\hat{x}_t := \\log x_t - \\log x$ と定義するか, $\\hat{x}_t := \\frac{x_t - x}{x}$ と定義するかは異なりますが, 近似的にはどちらも同じ意味持ちます.\n\n::: {.cell fig-width='80%' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Approximation of the deviation from the steady state](11-linearization_files/figure-pdf/fig-hat-output-1.svg){#fig-hat}\n:::\n:::\n\n\n\n@fig-hat にあるように, $\\hat{x}_t$ は定常状態 $x$ に十分近ければ, どちらの定義もほとんど同じ値をとることがわかります.\n\n\n::: {#thm-taylor-approx}\n\n## 1次近似\n\n1変数関数 $f$ の点 $x$ において, 以下が成り立つ.\n\n$$\nf(x_t) = f(x) + f'(x)(x_t - x) + R(x_t).\n$$\n\nここで, $R(x_t)$ は高次の剰余項であり, $\\lim_{x_t \\rightarrow x} \\frac{R(x_t)}{ |x_t - x| } = 0$ が成り立つ. したがって, $x$ の近傍では剰余項が十分小さいため, 以下の近似が成り立つ.\n\n$$\nf(x_t) \\approx f(x) + f'(x)(x_t - x).\n$$\n\n多変数関数 $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ の場合も同様に近似できる.\n\n$$\nf(\\mathbf{x}_t) \\approx f(\\mathbf{x}) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})(x_{t,i} - x_i).\n$$\n\n:::\n\n## 対数線形化\n\n::: {#prp-log-linearization}\n\n### 対数線形化の一般形\n\n$y_t = f(\\mathbf{x}_t)$ の $\\mathbf{x}$ 近傍での線形化は以下のように表される.\n\n$$\n\\hat{y}_t = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{x_i}{f(\\mathbf{x})}\\hat{x}_{i, t}.\n$$\n\n:::\n\n_証明_\n\nStep 1: 両辺の対数をとる.\n\n$$\n\\log y_t = \\log f(\\mathbf{x}_t)\n$$\n\nStep 2: 両辺をそれぞれ一次近似する.\n\n$$\n\\begin{aligned}\nLHS &\\approx \\log y + \\underbrace{\\frac{1}{y}(y_t - y)}_{\\hat{y}_t} \\\\\nRHS &\\approx \\log f(\\mathbf{x}) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{1}{f(\\mathbf{x})}(x_{i, t} - x_i) \\\\\n&= \\log f(\\mathbf{x}) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{x_i}{f(\\mathbf{x})}\\underbrace{\\frac{x_{i, t} - x_i}{x_i}}_{\\hat{x}_{i, t}}.\n\\end{aligned}\n$$\n\nStep 3: 定常状態 $\\log y = \\log f(\\mathbf{x})$ を両辺から引く.\n\n$$\n\\hat{y}_t = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{x_i}{f(\\mathbf{x})}\\hat{x}_{i, t}.\n$$\n\n\n### 例\n\n::: {#exm-lin-prod}\n\n## Cobb-Douglas Production Function\n\n$$\nY_t = A_t K_t^{\\alpha} L_t^{1 - \\alpha} \\Rightarrow\n\\hat{Y}_t \\approx \\hat{A}_t + \\alpha \\hat{K}_t + (1 - \\alpha) \\hat{L}_t.\n$$\n\n:::\n\n::: {.proof}\n\n1. Logをとる\n    - $\\log Y_t = \\log A_t + \\alpha \\log K_t + (1-\\alpha)\\log L_t$\n1. 線形近似\n    - $LHS = \\log Y + \\hat{Y_t}$\n    - $RHS = \\log A + \\alpha \\log K + (1-\\alpha)\\log L + \\hat{A}_t + \\alpha \\hat{K}_t + (1-\\alpha) \\hat{L}_t$\n1. 定常状態を引く\n    - $\\hat{Y}_t = \\hat{A}_t + \\alpha \\hat{K}_t + (1 - \\alpha) \\hat{L}_t$\n\n:::\n\n::: {#exm-lin-euler-eq}\n\n## Ramsey Model\n\n$$\n\\begin{aligned}\n&c_t^{-\\sigma} = \\beta(1-\\delta+\\alpha k_{t}^{\\alpha-1})c_{t+1}^{-\\sigma} \\\\\n& k_t^\\alpha + (1-\\delta)k_t = c_t + k_{t+1}\n\\end{aligned}\n\\quad\\Rightarrow\\quad\n\\begin{aligned}\n\\hat{c}_{t+1} &= \\hat{c}_t + \\frac{\\beta \\alpha (\\alpha-1)k^{\\alpha-1}}{\\sigma} \\hat{k}_t \\\\\n\\hat{k}_{t+1} &= -\\frac{c}{k} \\hat{c}_t + \\frac{1}{\\beta} \\hat{k}_t.\n\\end{aligned}\n$$\n\n:::\n\n::: {.proof}\n<br>\n**Step 1**: Logをとる\n\n$$\n\\begin{aligned}\n-\\sigma \\log c_t &= \\log \\beta + \\log(1-\\delta+\\alpha k_{t}^{\\alpha-1}) - \\sigma \\log c_{t+1} \\\\\n\\log (k_t^{\\alpha} + (1-\\delta)k_t) &= \\log (c_t + k_{t+1})\n\\end{aligned}\n$$\n\n**Step 2**: 線形近似\n\n$$\n\\begin{aligned}\nLHS_1 &\\approx -\\sigma \\hat{c}_t + LHS_1^*\\\\\nRHS_1 &\\approx \\frac{\\alpha(\\alpha-1)k^{\\alpha-1}}{1-\\delta + \\alpha k^{\\alpha-1}}\\hat{k}_{t} +\n- \\sigma \\hat{c}_{t+1} + RHS_1^*\\\\\nLHS_2 &\\approx \\frac{\\alpha k^{\\alpha-1} + 1 - \\delta}{k^{\\alpha} + (1-\\delta)k} k\\hat{k}_t + LHS_2^*\\\\\nRHS_2 &\\approx \\frac{c}{c + k} \\hat{c}_t + \\frac{k}{c + k} \\hat{k}_{t+1} + RHS_2^*\n\\end{aligned}\n$$\n\nなお, $LHS_1^*, RHS_1^*, LHS_2^*, RHS_2^*$ は定常状態における値 (次のステップで消去される).\n\n**Step 3**: 定常状態を引く\n\n$$\n\\begin{aligned}\n-\\sigma \\hat{c}_t &= \\frac{\\alpha(\\alpha-1)k^{\\alpha-1}}{1-\\delta + \\alpha k^{\\alpha-1}}\\hat{k}_{t} - \\sigma \\hat{c}_{t+1} \\\\\n\\frac{\\alpha k^{\\alpha-1} + 1 - \\delta}{k^{\\alpha} + (1-\\delta)k}k \\hat{k}_t &= \\frac{c}{c + k} \\hat{c}_t + \\frac{k}{c + k} \\hat{k}_{t+1}\n\\end{aligned}\n$$\n\nなお, 定常状態では\n\n$$\n\\begin{aligned}\nc^{-\\sigma} &= \\beta(1-\\delta+\\alpha k^{\\alpha-1})c^{-\\sigma} \\\\\nk^\\alpha + (1-\\delta)k &= c + k\n\\end{aligned}\n$$\n\nが成り立つため, 整理すると以下を得ます.\n\n$$\n\\begin{aligned}\n\\hat{c}_{t+1} &= \\hat{c}_t + \\frac{\\beta \\alpha (\\alpha-1)k^{\\alpha-1}}{\\sigma} \\hat{k}_t \\\\\n\\hat{k}_{t+1} &= -\\frac{c}{k} \\hat{c}_t + \\frac{1}{\\beta} \\hat{k}_t.\n\\end{aligned}\n$$\n\n:::\n\n## 対数線形化のもう一つの方法\n\n$y_t = f(\\mathbf{x}_t)$ の対数線形化は以下のように行うこともできます. この場合は, $\\hat{z}_t := \\log x_t - \\log x$ と定義します.\n\n**Step 1:** $z_t = \\exp(\\log z_t)$ と置き換える.\n\n$$\n\\exp(\\log y_t) = f(\\exp(\\log \\mathbf{x}_t)).\n$$\n\n**Step 2:** $\\log z_t$ に対しての線形近似を行う.\n\n$$\n\\begin{aligned}\nLHS &\\approx \\exp(\\log y) + \\exp(\\log y)(\\log y_t - \\log y) = y + y \\hat{y}_t \\\\\nRHS &\\approx f(\\exp(\\log \\mathbf{x})) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial \\log x_i}(\\exp(\\log \\mathbf{x}))(\\log x_{i, t} - \\log x_i) \\\\\n&= f(\\mathbf{x}) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{\\partial x_i}{\\partial \\log x_i}(\\log x_{i, t} - \\log x_i) \\\\\n&= f(\\mathbf{x}) + \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})x_i\\hat{x}_{i, t}.\n\\end{aligned}\n$$\n\n**Step 3:** 両辺から定常状態 $y = f(\\mathbf{x})$ を引き, 定常状態で割る.\n\n$$\n\\hat{y}_t = \\sum_{i=1}^n \\frac{\\partial f}{\\partial x_i}(\\mathbf{x})\\frac{x_i}{f(\\mathbf{x})}\\hat{x}_{i, t}.\n$$\n\nよって, この方法でも同じ結果が得られます.\n\n::: {#exm-lin-ramsey-alt}\n\n## Ramsey Model\n\n$$\n\\begin{aligned}\n&c_t^{-\\sigma} = \\beta(1-\\delta+\\alpha k_{t}^{\\alpha-1})c_{t+1}^{-\\sigma} \\\\\n& k_t^\\alpha + (1-\\delta)k_t = c_t + k_{t+1}\n\\end{aligned}\n\\quad\\Rightarrow\\quad\n\\begin{aligned}\n\\hat{c}_{t+1} &= \\hat{c}_t + \\frac{\\beta \\alpha (\\alpha-1)k^{\\alpha-1}}{\\sigma} \\hat{k}_t \\\\\n\\hat{k}_{t+1} &= -\\frac{c}{k} \\hat{c}_t + \\frac{1}{\\beta} \\hat{k}_t.\n\\end{aligned}\n$$\n\n:::\n\n::: {.proof}\n<br>\n\n**Step 1**: 置き換え\n\n$$\n\\begin{aligned}\n&\\exp(-\\sigma \\log c_t) = \\beta(1-\\delta+\\alpha \\exp((\\alpha-1)\\log k_{t}))\\exp(-\\sigma \\log c_{t+1}) \\\\\n&  \\exp(\\alpha \\log k_t) + (1-\\delta)\\exp(\\log k_t) = \\exp(\\log c_t) + \\exp(\\log k_{t+1})\n\\end{aligned}\n$$\n\n**Step 2**: 線形近似\n\n$$\n\\begin{aligned}\nLHS_1 &\\approx LHS_1^* + \\exp(-\\sigma \\log c)(-\\sigma)(\\log c_t - \\log c) \\\\\n&= LHS_1^* - \\sigma c^{-\\sigma} \\hat{c}_t \\\\\nRHS_1 &\\approx RHS_1^* + \\beta \\alpha(\\alpha-1)\\exp(-\\sigma \\log c)\\exp((\\alpha-1)\\log k)(\\log k_t - \\log k) \\\\\n&+\\beta (1-\\delta+\\alpha \\exp((\\alpha-1)\\log k))\\exp(-\\sigma \\log c)(-\\sigma)(\\log c_{t+1} - \\log c) \\\\\n&= RHS_1^* + \\beta \\alpha (\\alpha-1) k^{\\alpha-1} c^{-\\sigma} \\hat{k}_t - \\sigma \\beta(1-\\delta+\\alpha k^{\\alpha-1}) c^{-\\sigma} \\hat{c}_{t+1} \\\\\nLHS_2 &\\approx LHS_2^* + (\\alpha\\exp(\\alpha \\log k) + (1-\\delta)\\exp(\\log k))(\\log k_t - \\log k) \\\\\n&= LHS_2^* + \\left(\\alpha k^{\\alpha-1} + 1 - \\delta\\right) k \\hat{k}_t \\\\\nRHS_2 &\\approx RHS_2^* + \\exp(\\log c)(\\log c_t - \\log c) + \\exp(\\log k)(\\log k_{t+1} - \\log k) \\\\\n&= RHS_2^* + c \\hat{c}_t + k \\hat{k}_{t+1}\n\\end{aligned}\n$$\n\n**Step 3**: 定常状態を引き, 定常状態で割る\n\n$$\n\\begin{aligned}\n\\hat{c}_{t+1} &= \\hat{c}_t + \\frac{\\beta \\alpha (\\alpha-1)k^{\\alpha-1}}{\\sigma} \\hat{k}_t \\\\\n\\hat{k}_{t+1} &= -\\frac{c}{k} \\hat{c}_t + \\frac{1}{\\beta} \\hat{k}_t.\n\\end{aligned}\n$$\n\nここで, $\\frac{1}{\\beta} = 1 - \\delta + \\alpha k^{\\alpha-1}$ を用いた.\n\n:::\n\n\n## (補論) 数値計算例\n\n以下のラムゼイモデルのサドルパスを数値計算してみましょう.\n\n$$\n\\begin{aligned}\n&c_t^{-\\sigma} = \\beta(1-\\delta+\\alpha k_{t}^{\\alpha-1})c_{t+1}^{-\\sigma} \\\\\n& k_t^\\alpha + (1-\\delta)k_t = c_t + k_{t+1}\n\\end{aligned}\n\\quad\\Rightarrow\\quad\n\\begin{aligned}\n\\hat{c}_{t+1} &= \\hat{c}_t + \\frac{\\beta \\alpha (\\alpha-1)k^{\\alpha-1}}{\\sigma} \\hat{k}_t \\\\\n\\hat{k}_{t+1} &= -\\frac{c}{k} \\hat{c}_t + \\frac{1}{\\beta} \\hat{k}_t.\n\\end{aligned}\n$$\n\nパラメータは標準的な値 $\\alpha = 0.36, \\beta = 0.96, \\delta = 0.1, \\sigma = 1.5$ を使います.\n\n::: {.cell execution_count=1}\n\n::: {#params .cell-output .cell-output-display execution_count=1}\n```\n(α = 0.36, β = 0.96, δ = 0.1, σ = 1.5)\n```\n:::\n:::\n\n\n\n定常状態は以下のように計算できます.\n\n$$\n\\begin{aligned}\nc &= k^{\\alpha} - \\delta k \\\\\nk &= \\left(\\frac{1/\\beta - (1-\\delta)}{\\alpha}\\right)^{\\frac{1}{\\alpha-1}}\n\\end{aligned}\n$$\n\n::: {.cell execution_count=1}\n\n::: {#steady-state .cell-output .cell-output-display execution_count=1}\n```\n(4.294048197345121, 1.2603826653318553)\n```\n:::\n:::\n\n\n\n### 線形モデル\n\nモデルは以下のように書き換えることができます.\n\n$$\n\\begin{pmatrix}\n\\hat{c}_{t+1} \\\\\n\\hat{k}_{t+1}\n\\end{pmatrix}\n=\n\\underbrace{\\begin{pmatrix}\n1 & \\frac{\\beta \\alpha (\\alpha-1) k^{\\alpha-1}}{\\sigma} \\\\\n-\\frac{c}{k} & \\frac{1}{\\beta}\n\\end{pmatrix}}_{M}\n\\begin{pmatrix}\n\\hat{c}_t \\\\\n\\hat{k}_t\n\\end{pmatrix}\n$$\n\nここでは, $\\hat{k}_0 = 0.01$ (定常状態から1%の増加) からの変化を考えます. Saddle path 上の $\\hat{c}_0$ を求めるために, 固有値分解を行います.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nEigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}\nvalues:\n2-element Vector{Float64}:\n 0.8886746067491774\n 1.1529920599174894\nvectors:\n2×2 Matrix{Float64}:\n -0.462214   0.354629\n -0.886768  -0.935007\n```\n:::\n:::\n\n\n\n固有値が1より小さいものが安定な挙動を示すので, 対応した固有ベクトルが saddle path であることがわかります. したがって, $\\hat{c}_0$ は以下のように計算できます.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n0.005212347782677869\n```\n:::\n:::\n\n\n\n初期値が分かったため, あとは $M$ を使って順番に $\\hat{c}_t, \\hat{k}_t$ を求めていきます.\n\n\n\n\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Impulse Response and Phase Diagram of the Ramsey Model (Linearized)](11-linearization_files/figure-pdf/fig-ramsey-lin-output-1.svg){#fig-ramsey-lin}\n:::\n:::\n\n\n\n\n### 非線形モデル\n\n非線形モデルは以下のように書き換えることができます.\n$$\n\\begin{aligned}\nc_{t+1} &= (\\beta(1-\\delta+\\alpha k_{t}^{\\alpha-1}))^{\\frac{1}{\\sigma}} c_t \\\\\nk_{t+1} &= k_t^\\alpha + (1-\\delta)k_t - c_t \\\\\n\\end{aligned}\n$$\n\n線形モデルと異なり, 非線形モデルでは Saddle path の解析解が得られないため, $\\hat{k}_0 = 0.01$ に対応した $c_0$ を数値的に求める必要があります. ここでは十分長い期間 ($T = 100$) に定常状態に収束すると考えて $c_0$ の値を求める Shooting Method を使います.\n\n\n\n\n::: {.cell fig-width='80%' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Impulse Response and Phase Diagram of the Ramsey Model (Nonlinearized)](11-linearization_files/figure-pdf/fig-ramsey-nl-output-1.svg){#fig-ramsey-nl}\n:::\n:::\n\n\n\n@fig-ramsey-nl に示すように, 線形化モデルと非線形モデルのIRFやSaddle Pathはほとんど一致していることがわかります.\n\n",
    "supporting": [
      "11-linearization_files/figure-pdf"
    ],
    "filters": []
  }
}