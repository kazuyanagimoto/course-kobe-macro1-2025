{
  "hash": "8f1cd7fee3c920fffb6eea4b96fdc210",
  "result": {
    "engine": "julia",
    "markdown": "---\nengine: julia\n---\n\n# Dynamic Programming\n\n\n\n\n## Introduction\n\nこの章では, 動的計画法 (Dynamic Programming) による非線形モデルの数値解法について学びます.　次のベルマン方程式を解くことを考えます.\n\n$$\nV(k, z) = \\max_{k'} U\\left(zf(k) + (1-\\delta)k - k', 1-n\\right) + \\beta \\mathbb{E}[V(k', z') | z].\n$$\n\nsubject to\n\n$$\nc + k' = zf(k) + (1-\\delta)k.\n$$\n\nここで, モデルを「解く」とは, 価値関数 $V(k, z)$ や政策関数 $c = g_c(k, z)$, $k' = g_k(k, z)$, を数値的に求めることを意味します. つまり, 次のステップを踏みます.\n\n1. グリッドの離散化: $k = k_1, k_2, \\dots, k_I$, $z = z_1, z_2, \\dots, z_J$\n1. 価値関数の計算: 各 $(k_i, z_j)$ に対して $V(k_i, z_j)$ を計算\n1. 政策関数の計算: 各 $(k_i, z_j)$ に対して $c = g_c(k_i, z_j)$ , $k' = g_k(k_i, z_j)$, を計算\n\nいきなり確率過程を考えるのは難しいので, まずは確定的な場合から始めます.\n\n## Deterministic Case\n\n確定的な場合の次のベルマン方程式を考えます.\n\n$$\nV(k) = \\max_{k'} \\left\\{u(f(k) + (1-\\delta)k - k') + \\beta V(k')\\right\\}.\n$$\n\nこの問題を数値的に解く方法には, 大きく分けて2つの方法があります.\n\n1. **Value Function Iteration**\n    - ベルマン方程式の不動点を直接求める方法\n    - 収束性が保証されているが, 収束速度は比較的遅い\n2. **Policy Function Iteration**\n    - オイラー方程式の不動点を求める方法\n    - 収束性は保証されていないが, 収束速度は比較的速い\n\n数値計算に用いるために, 以下の関数形とパラメータを仮定します.\n\n- $u(c) = \\log c$\n- $f(k) = k^\\alpha$\n- $\\beta = 0.96$\n- $\\delta = 0.1$\n- $\\alpha = 0.36$\n\n\n\n\n### Value Function Iteration\n\n::: {.callout-note}\n\n## Value Function Iteration\n\n1. $k$ の定義域を $[k_{\\min}, k_{\\max}]$ を $n$ 個のグリッドポイントに分割する.\n1. $V(k)$ の初期値 $V^0$ を適当に設定する. つまり, $V^0 = (V_0^0, V_1^0, \\dots, V_n^0)$ に適当な値を設定する.\n1. $V^0$ をベルマン方程式の右辺に代入し, 各 $k_i$ に対して $V_i^1$ を計算する.\n    - $k_i$ に対する最適な $k'$ を求めるために, グリッドポイント全てを試し, 最大化を行う.\n1. 2-3を繰り返す. 収束条件は以下のように設定する.\n    - $|V^N - V^{N-1}| < \\varepsilon$\n    - $|V^N - V^{N-1}|$ はベクトルのノルム\n    - $\\varepsilon$ は十分小さな値を設定する. 例えば, $\\epsilon = 10^{-6}$ とする\n\n:::\n\nこのアルゴリズムは, 縮小写像定理 (Contraction Mapping Theorem) に基づいており, 収束が保証されています. 詳しくは @stokey1989 の第3章を参照してください. また, このような収束の閾値 $\\varepsilon$ を tolerance と呼ぶことがあります.\n\n\n\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Value Function Computed by Value Function Iteration (VFI).](14-dp_files/figure-pdf/fig-vfi-output-1.svg){#fig-vfi}\n:::\n:::\n\n\n\nなお, 各イタレーションでは, $k$ に対する最適な $k'$ や $c$ を求めています. それらを記録しておくことで, 政策関数 $c = g_c(k)$ や $k' = g_k(k)$ を求めることができます.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Policy Function Computed by Value Function Iteration (VFI).](14-dp_files/figure-pdf/fig-policy-function-output-1.svg){#fig-policy-function}\n:::\n:::\n\n\n\nこれを見ると, 政策関数の計算精度がやや低いことがわかります. グリッドポイントを増やす, 補完を用いるなどの工夫で対処できますが, より高速で高精度な方法として, 次に紹介する Policy Function Iteration を用いる方法があります.\n\n### Policy Function Iteration\n\n上記のベルマン方程式から, 以下のオイラー方程式が導出されます.\n\n$$\nu'(c) = \\beta u'(c')\\left(f'(k') + (1-\\delta)\\right).\n$$\n\nここで, 政策関数 $c' = g_c(k')$ と予算制約 $k' = f(k) + (1-\\delta)k - c$ を導入すると, 上記のオイラー方程式は以下のように書き換えられます.\n\n$$\nu'(c) = \\beta u'(g_c(f(k) + (1-\\delta)k - c))\\left(f'(f(k) + (1-\\delta)k - c) + (1-\\delta)\\right).\n$$\n\nこの時, $g_c^{0}(k)$ を所与とした時に $c$ について解くと新しい政策関数 $g_c^{1}(k)$ が得られます. この政策関数繰り返し更新することで, 政策関数の不動点を求めることができます.\n\n::: {.callout-note}\n\n## Policy Function Iteration\n\n1. $k$ の定義域を $[k_{\\min}, k_{\\max}]$ を $n$ 個のグリッドポイントに分割する\n1. $g_c(k)$ の初期値 $g_c^0$ を適当に設定する. つまり, $g_c^0 = (g_{c,0}^0, g_{c,1}^0, \\dots, g_{c,n}^0)$ に適当な値を設定する.\n1. $g_c^0$ をオイラー方程式の右辺に代入し, 各 $k_i$ に対して $g_{c,i}^1$ を計算する.\n1. 2-3を繰り返す. 収束条件は以下のように設定する.\n    - $|g_c^N - g_c^{N-1}| < \\varepsilon$   \n    - $|g_c^N - g_c^{N-1}|$ はベクトルのノルム\n    - $\\varepsilon$ は十分小さな値を設定する. 例えば, $\\epsilon = 10^{-6}$ とする\n:::\n\nまた, ここから $k' := g_k(k) = f(k) + (1-\\delta)k - g_c(k)$ が求められます.\n\n::: {#pfi-deterministic .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nConverged in 80 iterations.\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Policy Function Computed by Policy Function Iteration (PFI).](14-dp_files/figure-pdf/fig-policy-function-pfi-output-1.svg){#fig-policy-function-pfi}\n:::\n:::\n\n\n\nさらに, $g_c(k), g_k(k)$ から価値関数 $V(k)$ を求める方法は主に2つあります.\n\n1. $V(k) \\leftarrow u(g_c(k)) + \\beta V(g_k(k))$ を用いて $V(k)$ の不動点を求める方法 (VFI)\n1. 線形方程式\n    1. 離散化された $k$ から $k'$ への遷移行列 $P$ を求める. グリッド $k_i$ が $k_j$ と $k_{j+1}$ の間に遷移する場合, 以下のように定義します.\n        - $P_{i, j} = \\frac{k_{j+1} - g_k(k_i)}{k_{j+1} - k_j}$\n        - $P_{i, j+1} = \\frac{g_k(k_i) - k_j}{k_{j+1} - k_j}$\n        - $P_{i, k} = 0$, $k \\neq j, j+1$\n    1. $u, V$ を $u(g_c(k)), V(k)$ からなる離散化されたベクトルとすると, $V = u + \\beta P V$ となる\n    1. $V = (I - \\beta P)^{-1} u$ により $V$ を求めることができる\n\nここでは, より高速な線型方程式を用いる方法を実装します. より速度を求める場合, 遷移行列はほとんどの要素がゼロであるため, 疎行列 (Sparse Matrix) を用いることで高速化する可能性があります. Juliaの場合, `SparseArrays.jl` で実装されています.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Value Function from PFI and Linear Equation](14-dp_files/figure-pdf/fig-pfi-vf-output-1.svg){#fig-pfi-vf}\n:::\n:::\n\n\n\nまた, VFIよりもPFIの方が実行速度が速いことも確認できます.\n\n::: {.cell execution_count=1}\n\n::: {#bm-vfi .cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 71 samples with 1 evaluation per sample.\n Range (min … max):  70.419 ms … 78.563 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     70.791 ms              ┊ GC (median):    0.00%\n Time  (mean ± σ):   71.153 ms ±  1.067 ms  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n     ▃▅█▃                                                      \n  ▄▃▄████▃▃▆▄▃▄▁▁▃▃▃▃▄▄▅▁▃▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▁\n  70.4 ms         Histogram: frequency by time        74.3 ms <\n\n Memory estimate: 265.53 KiB, allocs estimate: 586.\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n\n::: {#bm-pfi .cell-output .cell-output-display execution_count=1}\n```\nBenchmarkTools.Trial: 132 samples with 1 evaluation per sample.\n Range (min … max):  37.146 ms …  42.980 ms  ┊ GC (min … max): 0.00% … 0.00%\n Time  (median):     38.050 ms               ┊ GC (median):    0.00%\n Time  (mean ± σ):   38.109 ms ± 834.360 μs  ┊ GC (mean ± σ):  0.00% ± 0.00%\n\n    ▄▄▂▁▃  ▂▂ ▁▃▃█▆▃                                            \n  ▅██████▅▅██▇██████▇▅▁▁▅▁▁▅▁▅▇▅▁▁▁▁▅▁▇▁▅▅▅▅▇▁▁▁▁▁▁▅▅▅▅▁▁▁▁▁▁▅ ▅\n  37.1 ms       Histogram: log(frequency) by time      40.8 ms <\n\n Memory estimate: 468.94 KiB, allocs estimate: 340.\n```\n:::\n:::\n\n\n\n## Stochastic Case\n\n$V(k, z)$ の数値計算するためには, $z$ の状態空間も離散化する必要があります. この時, 同時に確率過程 (AR(1) process) も離散化, つまりマルコフ過程として近似する必要があります. ここで, $z = z_1, \\dots, z_J$ に離散化し, 各状態間の遷移確率を $J \\times J$ 行列の $\\Lambda$ とします. すると, ベルマン方程式は以下のようになります.\n\n$$\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\sum_{z'} \\Lambda(z, z') V(k', z')\\right\\}.\n$$\n\nこれはただ足し算の回数が増えただけで, 基本的には確定的な場合と同じです. AR(1) プロセスを離散化する方法として, ここでは Tauchen Method [@tauchen1986] を用います.\n\n### Tauchen Method\n\n実数列 $x_t$ が以下のAR(1)過程に従うとします.\n\n$$\nx_{t+1} = (1 - \\rho) \\mu + \\rho x_t + \\sigma \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, 1).\n$$\n\nこれを $n$ 個のグリッドポイント $\\{x_1, \\dots, x_n\\}$ におけるマルコフ過程として離散化することを考えます. すなわち, 以下のような遷移確率行列 $\\Lambda$ を考えます.\n\n$$\n\\begin{pmatrix}\nx_{1, t+1} \\\\\n\\vdots \\\\\nx_{n, t+1}\n\\end{pmatrix} =\n\\begin{pmatrix}\n\\lambda_{1, 1} & \\cdots & \\lambda_{1, n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\n\\lambda_{n, 1} & \\cdots & \\lambda_{n, n}\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{1, t} \\\\\n\\vdots \\\\\nx_{n, t}\n\\end{pmatrix}\n$$\n\nここで, $\\lambda_{i, j} = \\Pr(x_{t+1} = x_j \\mid x_t = x_i)$ であり, $\\sum_{j=1}^{n} \\lambda_{i, j} = 1$ が成り立ちます.\nこの遷移確率行列を求める方法として, Tauchen Method が知られています.\n\n::: {.callout-note}\n\n## Tauchen Method\n\n1. $x$ の定義域 を $[x_{\\min}, x_{\\max}]$ を $n$ 個のグリッドポイントに分割する. 通常は $x$ が従う分布の $3\\sigma$ 程度の範囲を考える.\n1. グリッドポイント $x_i$ から $x_j$ に遷移する確率を以下のように定義する.\n\n$$\n\\begin{aligned}\n\\lambda_{i, 1} &= \\Phi\\left(\\frac{x_1 + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) \\\\\n\\lambda_{i, j} &= \\Phi\\left(\\frac{x_j + \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) - \\Phi\\left(\\frac{x_{j} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right) & (2 \\leq j \\leq n-1) \\\\\n\\lambda_{i, n} &= 1 - \\Phi\\left(\\frac{x_{n} - \\frac{d}{2} - (1 - \\rho) \\mu - \\rho x_i}{\\sigma}\\right)\n\\end{aligned}\n$$\n\n:::\n\n![**Visualization of Tauchen Method**. $\\mu = 0$.](/static/cetz/tauchen_method.svg){#fig-tauchen-method width=100%}\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nx = -6.782472016116854:3.4412360080584268:6.982472016116853\n```\n:::\n\n::: {#tauchen-method .cell-output .cell-output-display execution_count=1}\n```\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n```\n:::\n:::\n\n\n\n実用上は `QuantEcon.jl` の `tauchen` 関数を利用するのがいいでしょう.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nmc.state_values = -5.8824720161168536:3.4412360080584268:7.8824720161168536\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n```\n:::\n:::\n\n\n\nただし, ここでは AR(1) process が以下のように定義されていることに注意してください.\n\n$$\ny_{t+1} = \\mu + \\rho y_{t} + \\varepsilon_{t+1}, \\quad \\varepsilon_{t+1} \\sim \\mathcal{N}(0, \\sigma^2).\n$$\n\nそのため, $\\mathbb{E}[y_{t}] = \\frac{\\mu}{1-\\rho}$ となります.\n上の例では, $\\mu = 0.1$, $\\rho = 0.9$, $\\sigma = 1.0$ としているため, $\\mathbb{E}[y_{t}] = 1.0$ となります.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n1.0\n```\n:::\n:::\n\n\n\nAR(1) processの期待値を任意の値 $\\tilde{\\mu}$ に設定するためには, $\\mu = (1-\\rho)\\tilde{\\mu}$ とすればよいです.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nmc.state_values = -6.782472016116854:3.4412360080584268:6.982472016116853\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n5×5 Matrix{Float64}:\n 0.849051     0.150945     3.84556e-6  1.22125e-15  0.0\n 0.0194737    0.896192     0.0843336   7.26002e-7   1.11022e-16\n 1.22258e-7   0.04266      0.91468     0.04266      1.22258e-7\n 7.34696e-17  7.26002e-7   0.0843336   0.896192     0.0194737\n 3.45903e-30  1.23783e-15  3.84556e-6  0.150945     0.849051\n```\n:::\n:::\n\n\n\n### Policy Function Iteration\n\nAR(1) process を $\\Lambda$ で離散化した後のベルマン方程式は以下のようになります.\n\n$$\nV(k, z) = \\max_{k'} \\left\\{u(f(k, z) + (1-\\delta)k - k') + \\beta \\sum_{z'} \\Lambda(z, z') V(k', z')\\right\\}.\n$$\n\nVFIを用いる場合, 実装は価値関数 $V$ の次元を $z$ のために1つ増やし, ベルマン方程式の通り実装するだけです. 実装はあまり難しくありませんが, 精度があまり良くないためここでは紹介しません. 気になる場合は [マクロIVの講義資料](https://kazuyanagimoto.com/course-kobe-macro4-2025/lecture/01-3-dynamic-model.html#value-function-iteration-2) を参考にしてください.\n\nPFIを用いる場合, オイラー方程式は以下のようになります.\n\n$$\nu'(c) = \\beta \\sum_{z'} \\Lambda(z, z') u'(c')(f'(k', z') + (1-\\delta)).\n$$\n\n::: {#model-stochastic .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\nConverged in 84 iterations.\n```\n:::\n:::\n\n\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Policy Function Computed by Value Function Iteration (VFI) in Stochastic Case.](14-dp_files/figure-pdf/fig-policy-function-stochastic-output-1.svg){#fig-policy-function-stochastic}\n:::\n:::\n\n\n\nここから価値関数を求めるアルゴリズムは以下のような手順になります.\n\n- $V(k, z)$ は離散化されたグリッド上の行列 $\\{V_{i_k, i_z}\\}_{i_k = 1,\\dots,n_k, i_z=1,\\dots,n_z}$ である\n- $\\{V_{i_k, i_z}\\}$ をベクトル化した $\\widetilde{V}$ を考える. $\\widetilde{V}_{i_k + n_k(i_z - 1)} := V_{i_k, i_z}$\n- ある $i_k, i_z$ に対して, $k_{j} < g_{i_k, i_z} < k_{j+1}$ を満たす $j \\in \\{1,\\dots,n_k\\}$ を求める\n- $(k, z)$ から $(k', z')$ への遷移は, $\\widetilde{V}$ 上で $i_k + n_k(i_z - 1)$ から $i_{k'} + n_k(i_{z'} - 1)$ への遷移\n- 遷移行列 $P$ は以下のように定義され, 定義されていない要素は 0 とする.\n\n$$\n\\begin{aligned}\nP_{i_k + n_k(i_z - 1), j + n_k(i_{z'} - 1)} &= \\begin{cases}\n\\Lambda_{i_z, i_{z'}} \\frac{k_{j+1}-g_{i_k, i_z}}{k_{j+1} - k_j} & \\text{ if } 1 < j < n_k \\\\\n\\Lambda_{i_z, i_{z'}} & \\text{otherwise}.\n\\end{cases}\\\\\nP_{i_k + n_k(i_z - 1), j + 1 + n_k(i_{z'} - 1)} &= \\begin{cases}\n\\Lambda_{i_z, i_{z'}} \\frac{g_{i_k, i_z} - k_{j}}{k_{j+1} - k_j} & \\text{ if } 1 < j < n_k \\\\\n\\Lambda_{i_z, i_{z'}} & \\text{otherwise}.\n\\end{cases}\\\\\n\\end{aligned}\n$$\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![Value Function Computed by Value Function Iteration (VFI) in Stochastic Case.](14-dp_files/figure-pdf/fig-model-stochastic-output-1.svg){#fig-model-stochastic}\n:::\n:::\n\n\n\n",
    "supporting": [
      "14-dp_files/figure-pdf"
    ],
    "filters": []
  }
}